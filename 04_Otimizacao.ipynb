{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "393743b8",
   "metadata": {},
   "source": [
    "\n",
    "# Etapa 4 — Otimização e Tuning de Hiperparâmetros  \n",
    "### Projeto de Machine Learning — Previsão de Preço de Carros Usados  \n",
    "**Grupo:** Luiz Guilherme, Luis Thyago, Igor Emmanuel, João Paulo, Rafael Henrique  \n",
    "**Turma:** 4º Período • ADS • Turma B • Uninassau  \n",
    "**Dataset:** used_cars_price.csv  \n",
    "---  \n",
    "Este notebook contém todo o processo da etapa 4: baseline, tuning, comparação, avaliação final e salvamento do modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ca89c9",
   "metadata": {},
   "source": [
    "# Etapa 4 — Otimização e Tuning de Hiperparâmetros\n",
    "Notebook completo para a Etapa 4: Grid/Random Search, comparação de modelos, análise de erros e salvamento do modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37348023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"artifacts\", exist_ok=True)\n",
    "plt.rcParams[\"figure.figsize\"] = (8,6)\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fafaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tenta carregar CSV usado no etapa3\n",
    "if os.path.exists(\"used_cars_price.csv\"):\n",
    "    df = pd.read_csv(\"used_cars_price.csv\")\n",
    "elif os.path.exists(\"/mnt/data/used_cars_price.csv\"):\n",
    "    df = pd.read_csv(\"/mnt/data/used_cars_price.csv\")\n",
    "else:\n",
    "    if os.path.exists(\"data/used_cars_price.csv\"):\n",
    "        df = pd.read_csv(\"data/used_cars_price.csv\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Coloque 'used_cars_price.csv' na raiz do projeto ou em data/\")\n",
    "if 'car_id' in df.columns:\n",
    "    df = df.drop('car_id', axis=1)\n",
    "cols_numericas = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "for col in cols_numericas:\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "cols_categoricas = df.select_dtypes(include=['object']).columns\n",
    "for col in cols_categoricas:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "map_sim_nao = {'Sim': 1, 'Não': 0, 'Yes': 1, 'No': 0}\n",
    "binarias = ['air_conditioning', 'power_steering', 'power_windows', 'abs_brakes', \n",
    "            'sunroof', 'parking_sensors', 'imported']\n",
    "for col in binarias:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].map(map_sim_nao)\n",
    "df_model = pd.get_dummies(df, drop_first=True)\n",
    "X = df_model.drop('price_brl', axis=1)\n",
    "y = df_model['price_brl']\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.20, random_state=RANDOM_STATE)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18abb10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    return {\"R2\": r2_score(y_true, y_pred),\n",
    "            \"RMSE\": np.sqrt(mse),\n",
    "            \"MAE\": mean_absolute_error(y_true, y_pred)}\n",
    "def fmt_money(x):\n",
    "    if x >= 1_000_000: return f'{x*1e-6:.1f}M'\n",
    "    if x >= 1_000: return f'{x*1e-3:.0f}K'\n",
    "    return f'{x:.0f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66d1637",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = LinearRegression()\n",
    "baseline.fit(X_train, y_train)\n",
    "y_pred_train = baseline.predict(X_train)\n",
    "y_pred_val = baseline.predict(X_val)\n",
    "metrics_baseline_train = get_metrics(y_train, y_pred_train)\n",
    "metrics_baseline_val = get_metrics(y_val, y_pred_val)\n",
    "baseline_info = {\"model_name\": \"LinearRegression\",\n",
    "                 \"train_metrics\": metrics_baseline_train,\n",
    "                 \"val_metrics\": metrics_baseline_val}\n",
    "with open(\"artifacts/baseline_metrics.json\", \"w\") as f:\n",
    "    json.dump(baseline_info, f)\n",
    "baseline_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc0cc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = {}\n",
    "candidates[\"Ridge\"] = {\n",
    "    \"estimator\": Ridge(random_state=RANDOM_STATE),\n",
    "    \"search\": \"grid\",\n",
    "    \"param_grid\": {\"alpha\": [0.1, 1.0, 10.0, 50.0, 100.0]}\n",
    "}\n",
    "candidates[\"Lasso\"] = {\n",
    "    \"estimator\": Lasso(random_state=RANDOM_STATE, max_iter=5000),\n",
    "    \"search\": \"grid\",\n",
    "    \"param_grid\": {\"alpha\": [0.0001, 0.001, 0.01, 0.1, 1.0]}\n",
    "}\n",
    "candidates[\"RandomForest\"] = {\n",
    "    \"estimator\": RandomForestRegressor(random_state=RANDOM_STATE, n_jobs=-1),\n",
    "    \"search\": \"random\",\n",
    "    \"param_dist\": {\n",
    "        \"n_estimators\": [100,200,300,500],\n",
    "        \"max_depth\": [None, 10, 20, 30],\n",
    "        \"min_samples_split\": [2,5,10],\n",
    "        \"min_samples_leaf\": [1,2,4]\n",
    "    },\n",
    "    \"n_iter\": 30\n",
    "}\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    candidates[\"XGBoost\"] = {\n",
    "        \"estimator\": xgb.XGBRegressor(random_state=RANDOM_STATE, n_jobs=-1, objective=\"reg:squarederror\"),\n",
    "        \"search\": \"random\",\n",
    "        \"param_dist\": {\n",
    "            \"n_estimators\": [100,200,300],\n",
    "            \"max_depth\": [3,4,6,8],\n",
    "            \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "            \"subsample\": [0.6,0.8,1.0]\n",
    "        },\n",
    "        \"n_iter\": 30\n",
    "    }\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c890edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "results = {}\n",
    "X_tune = pd.concat([X_train, X_val], axis=0)\n",
    "y_tune = pd.concat([y_train, y_val], axis=0)\n",
    "for name, cfg in candidates.items():\n",
    "    est = cfg[\"estimator\"]\n",
    "    if cfg[\"search\"] == \"grid\":\n",
    "        gs = GridSearchCV(est, cfg[\"param_grid\"], cv=5, scoring=\"neg_root_mean_squared_error\", n_jobs=-1, return_train_score=True)\n",
    "        gs.fit(X_tune, y_tune)\n",
    "        results[name] = gs\n",
    "        joblib.dump(gs, f\"artifacts/{name}_GridSearch.joblib\")\n",
    "    else:\n",
    "        rs = RandomizedSearchCV(est, cfg[\"param_dist\"], n_iter=cfg.get(\"n_iter\",30), cv=5, scoring=\"neg_root_mean_squared_error\", random_state=RANDOM_STATE, n_jobs=-1, return_train_score=True)\n",
    "        rs.fit(X_tune, y_tune)\n",
    "        results[name] = rs\n",
    "        joblib.dump(rs, f\"artifacts/{name}_RandomSearch.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67137a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_rows = []\n",
    "for name, search in results.items():\n",
    "    best_params = search.best_params_\n",
    "    best_score = -search.best_score_\n",
    "    train_mean = None\n",
    "    if \"mean_train_score\" in search.cv_results_:\n",
    "        train_mean = -np.mean(search.cv_results_[\"mean_train_score\"])\n",
    "    summary_rows.append({\"model\": name, \"best_params\": best_params, \"cv_neg_rmse\": search.best_score_, \"cv_rmse\": best_score, \"train_cv_rmse_est\": train_mean})\n",
    "df_summary = pd.DataFrame(summary_rows).sort_values(\"cv_rmse\")\n",
    "df_summary.to_csv(\"artifacts/tuning_summary.csv\", index=False)\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f55eb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = df_summary.iloc[0][\"model\"]\n",
    "best_search = results[best_model_name]\n",
    "best_estimator = best_search.best_estimator_\n",
    "X_full_train = pd.concat([X_train, X_val], axis=0)\n",
    "y_full_train = pd.concat([y_train, y_val], axis=0)\n",
    "best_estimator.fit(X_full_train, y_full_train)\n",
    "joblib.dump(best_estimator, \"models/modelo_final.joblib\")\n",
    "best_model_name, best_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12946fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = joblib.load(\"models/modelo_final.joblib\")\n",
    "y_pred_test = loaded.predict(X_test)\n",
    "metrics_test = get_metrics(y_test, y_pred_test)\n",
    "with open(\"artifacts/final_test_metrics.json\", \"w\") as f:\n",
    "    json.dump(metrics_test, f)\n",
    "metrics_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5590f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "before = metrics_baseline_val\n",
    "after = metrics_test\n",
    "comp = pd.DataFrame([{\"metric\":\"R2\",\"before\":before[\"R2\"],\"after\":after[\"R2\"]},\n",
    "                     {\"metric\":\"RMSE\",\"before\":before[\"RMSE\"],\"after\":after[\"RMSE\"]},\n",
    "                     {\"metric\":\"MAE\",\"before\":before[\"MAE\"],\"after\":after[\"MAE\"]}])\n",
    "comp[\"improvement_pct\"] = comp.apply(lambda r: (r[\"before\"] - r[\"after\"]) / r[\"before\"] * 100 if r[\"metric\"]!=\"R2\" else (r[\"after\"] - r[\"before\"])/abs(r[\"before\"]+1e-9)*100, axis=1)\n",
    "comp.to_csv(\"artifacts/comparison_before_after.csv\", index=False)\n",
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba20932",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(y_test, y_pred_test, alpha=0.6)\n",
    "mn = min(y_test.min(), y_pred_test.min())\n",
    "mx = max(y_test.max(), y_pred_test.max())\n",
    "plt.plot([mn, mx], [mn, mx], 'r--', lw=2)\n",
    "plt.xlabel(\"Real (R$)\")\n",
    "plt.ylabel(\"Predito (R$)\")\n",
    "plt.title(\"Predito vs Real - Modelo Final\")\n",
    "plt.savefig(\"artifacts/pred_vs_real_final.png\")\n",
    "plt.close()\n",
    "\n",
    "residuals = y_test - y_pred_test\n",
    "fig, axs = plt.subplots(1,2, figsize=(14,5))\n",
    "axs[0].hist(residuals, bins=30)\n",
    "axs[0].axvline(0, color=\"k\", linestyle=\"--\")\n",
    "axs[0].set_title(\"Histograma dos Resíduos\")\n",
    "axs[1].scatter(y_pred_test, residuals, alpha=0.6)\n",
    "axs[1].axhline(0, color=\"k\", linestyle=\"--\")\n",
    "axs[1].set_xlabel(\"Predito\")\n",
    "axs[1].set_ylabel(\"Resíduo\")\n",
    "axs[1].set_title(\"Resíduos vs Predições\")\n",
    "plt.savefig(\"artifacts/residuals_final.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfefd338",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_errors = (y_test - y_pred_test).abs()\n",
    "df_errors = pd.DataFrame({\"real\": y_test, \"pred\": y_pred_test, \"abs_error\": abs_errors})\n",
    "df_errors_sorted = df_errors.sort_values(\"abs_error\", ascending=False).head(20)\n",
    "df_errors_sorted.to_csv(\"artifacts/worst_predictions_final.csv\", index=False)\n",
    "df_errors_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41f2f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(loaded, \"feature_importances_\"):\n",
    "    fi = pd.Series(loaded.feature_importances_, index=X.columns).sort_values(ascending=False).head(30)\n",
    "    fi.to_csv(\"artifacts/feature_importances.csv\")\n",
    "    plt.figure(figsize=(8,10))\n",
    "    fi.head(20).plot(kind=\"barh\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(\"Feature importances (top 20)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"artifacts/feature_importances.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5994e012",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded2 = joblib.load(\"models/modelo_final.joblib\")\n",
    "print(type(loaded2))\n",
    "print(\"Primeiras predições de teste:\", loaded2.predict(X_test.iloc[:5]).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d9570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    \"best_model\": best_model_name,\n",
    "    \"best_params\": best_search.best_params_,\n",
    "    \"test_metrics\": metrics_test,\n",
    "    \"baseline_val_metrics\": metrics_baseline_val\n",
    "}\n",
    "with open(\"artifacts/summary_etapa4.json\", \"w\") as f:\n",
    "    json.dump(summary, f)\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eeddc7",
   "metadata": {},
   "source": [
    "## Conclusões\n",
    "\n",
    "- Modelo final: **{best_model_name}**\n",
    "- Métricas no teste: ver `artifacts/final_test_metrics.json`\n",
    "- Comparação antes vs depois: ver `artifacts/comparison_before_after.csv`\n",
    "- Piores predições: ver `artifacts/worst_predictions_final.csv`\n",
    "- Próximos passos sugeridos: mais feature engineering, validação adicional por grupos (se houver), ensemble entre os melhores modelos, calibração de previsões e aumento de dados."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
